{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mervecakir1/Satellite-Segmentation/blob/main/huawei.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70JNPLtRGeqD"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "print(\"Torch:\", torch.__version__, \"| TorchVision:\", torchvision.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q4JqVetGqaU"
      },
      "outputs": [],
      "source": [
        "!pip install -U albumentations==1.4.8 albucore==0.0.12 opencv-python-headless==4.10.0.84 --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q segmentation-models-pytorch==0.3.3\n",
        "!pip install -q torchmetrics==1.3.2\n"
      ],
      "metadata": {
        "id": "mitfGMvAXKcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRiBWcpMGse0",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"mohammedjaveed/loveda-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N-SGZcfGtsK"
      },
      "outputs": [],
      "source": [
        "import os, glob, shutil, random\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "SRC = {\n",
        "    \"Train\": \"/kaggle/input/loveda-dataset/Train/Train/Urban\",\n",
        "    \"Val\"  : \"/kaggle/input/loveda-dataset/Val/Val/Urban\",\n",
        "    \"Test\" : \"/kaggle/input/loveda-dataset/Test/Test/Urban\",\n",
        "}\n",
        "DST_ROOT = \"/kaggle/working/LoveDA_Urban_subset\"\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "\n",
        "LIMITS = {\n",
        "    \"Train\": 480,\n",
        "    \"Val\"  : 220,\n",
        "    \"Test\" : 320,\n",
        "}\n",
        "\n",
        "RATIOS = {\n",
        "    \"Train\": 0.3,\n",
        "    \"Val\"  : 0.3,\n",
        "    \"Test\" : 0.3,\n",
        "}\n",
        "\n",
        "def ensure_dir(p): Path(p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def pick_subset(items, split):\n",
        "    if LIMITS.get(split) is not None:\n",
        "        n = min(LIMITS[split], len(items))\n",
        "    elif RATIOS.get(split) is not None:\n",
        "        n = max(1, int(len(items) * float(RATIOS[split])))\n",
        "    else:\n",
        "        n = len(items)\n",
        "    return random.sample(items, n) if n < len(items) else list(items)\n",
        "\n",
        "def copy_split(split):\n",
        "    urban_root = SRC[split]\n",
        "    src_img = os.path.join(urban_root, \"images_png\")\n",
        "    src_msk = os.path.join(urban_root, \"masks_png\")\n",
        "\n",
        "    dst_img = os.path.join(DST_ROOT, split, \"Image\")\n",
        "    dst_msk = os.path.join(DST_ROOT, split, \"Mask\")\n",
        "    ensure_dir(dst_img); ensure_dir(dst_msk)\n",
        "\n",
        "\n",
        "    img_files = sorted(glob.glob(os.path.join(src_img, \"*.png\")))\n",
        "    if not img_files:\n",
        "        raise FileNotFoundError(f\"Görsel bulunamadı: {src_img}\")\n",
        "\n",
        "\n",
        "    if os.path.isdir(src_msk):\n",
        "        msk_files = sorted(glob.glob(os.path.join(src_msk, \"*.png\")))\n",
        "        img_bases = {os.path.basename(p) for p in img_files}\n",
        "        msk_bases = {os.path.basename(p) for p in msk_files}\n",
        "        common = sorted(img_bases & msk_bases)\n",
        "        if not common:\n",
        "            raise RuntimeError(f\"Eşleşen image–mask yok: {src_img} vs {src_msk}\")\n",
        "\n",
        "        chosen = pick_subset(common, split)\n",
        "        for b in chosen:\n",
        "            shutil.copy(os.path.join(src_img, b), os.path.join(dst_img, b))\n",
        "            shutil.copy(os.path.join(src_msk, b), os.path.join(dst_msk, b))\n",
        "        print(f\" {split}: {len(chosen)} çift kopyalandı → {dst_img} & {dst_msk}\")\n",
        "\n",
        "    else:\n",
        "\n",
        "        chosen = pick_subset(img_files, split)\n",
        "        for p in chosen:\n",
        "            b = os.path.basename(p)\n",
        "            shutil.copy(p, os.path.join(dst_img, b))\n",
        "        print(f\" {split}: {len(chosen)} görüntü kopyalandı → {dst_img} (maske yok)\")\n",
        "\n",
        "for sp in [\"Train\", \"Val\", \"Test\"]:\n",
        "    copy_split(sp)\n",
        "\n",
        "\n",
        "def count_png(p): return len(glob.glob(os.path.join(p, \"*.png\")))\n",
        "for sp in [\"Train\", \"Val\", \"Test\"]:\n",
        "    ip = os.path.join(DST_ROOT, sp, \"Image\")\n",
        "    mp = os.path.join(DST_ROOT, sp, \"Mask\")\n",
        "    print(f\"{sp}: Image={count_png(ip)} | Mask={count_png(mp) if os.path.isdir(mp) else 0}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D3D1_QKGvc6"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "SRC_SUBSET = \"/kaggle/working/LoveDA_Urban_subset\"\n",
        "\n",
        "DST_PATCH  = \"/kaggle/working/LoveDA_Urban_256_subset\"\n",
        "\n",
        "PATCH = 256\n",
        "SPLITS = [\"Train\", \"Val\", \"Test\"]\n",
        "\n",
        "def ensure_dir(p): Path(p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def tile_and_save(img_np, out_dir_img, base, with_mask=False, msk_np=None, out_dir_msk=None):\n",
        "    h, w = img_np.shape[:2]\n",
        "    assert h % PATCH == 0 and w % PATCH == 0, f\"Boyutlar {h}x{w} PATCH={PATCH} ile tam bölünmüyor.\"\n",
        "    rows, cols = h // PATCH, w // PATCH\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            sy, sx = r*PATCH, c*PATCH\n",
        "            img_patch = img_np[sy:sy+PATCH, sx:sx+PATCH]\n",
        "            Image.fromarray(img_patch).save(os.path.join(out_dir_img, f\"{base}_r{r}_c{c}.png\"))\n",
        "            if with_mask and out_dir_msk is not None:\n",
        "                msk_patch = msk_np[sy:sy+PATCH, sx:sx+PATCH]\n",
        "                Image.fromarray(msk_patch.astype(np.uint8)).save(\n",
        "                    os.path.join(out_dir_msk, f\"{base}_r{r}_c{c}.png\")\n",
        "                )\n",
        "\n",
        "for sp in SPLITS:\n",
        "    src_img_dir = os.path.join(SRC_SUBSET, sp, \"Image\")\n",
        "    src_msk_dir = os.path.join(SRC_SUBSET, sp, \"Mask\")\n",
        "\n",
        "    out_img_dir = os.path.join(DST_PATCH, sp, \"Image\")\n",
        "    out_msk_dir = os.path.join(DST_PATCH, sp, \"Mask\")\n",
        "    ensure_dir(out_img_dir)\n",
        "\n",
        "    has_masks = os.path.isdir(src_msk_dir)\n",
        "    if has_masks:\n",
        "        ensure_dir(out_msk_dir)\n",
        "\n",
        "    img_files = sorted(glob.glob(os.path.join(src_img_dir, \"*.png\")))\n",
        "    assert img_files, f\"Görsel bulunamadı: {src_img_dir}\"\n",
        "\n",
        "    print(f\"\\n[{sp}] {len(img_files)} görüntü patch'leniyor...\")\n",
        "    for ip in tqdm(img_files):\n",
        "        base = os.path.splitext(os.path.basename(ip))[0]\n",
        "        img = np.array(Image.open(ip).convert(\"RGB\"))\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        if h % PATCH != 0 or w % PATCH != 0:\n",
        "            new_h = ((h // PATCH) + 1) * PATCH if h % PATCH != 0 else h\n",
        "            new_w = ((w // PATCH) + 1) * PATCH if w % PATCH != 0 else w\n",
        "\n",
        "            padded_img = np.zeros((new_h, new_w, 3), dtype=img.dtype)\n",
        "            padded_img[:h, :w] = img\n",
        "            img = padded_img\n",
        "            print(f\"Görüntü {base} boyutu {h}x{w} -> {new_h}x{new_w} padding uygulandı\")\n",
        "\n",
        "        if has_masks:\n",
        "            mp = os.path.join(src_msk_dir, base + \".png\")\n",
        "            if os.path.exists(mp):\n",
        "                msk = np.array(Image.open(mp))\n",
        "\n",
        "                if msk.shape[0] != img.shape[0] or msk.shape[1] != img.shape[1]:\n",
        "                    padded_msk = np.zeros((img.shape[0], img.shape[1]), dtype=msk.dtype)\n",
        "                    padded_msk[:msk.shape[0], :msk.shape[1]] = msk\n",
        "                    msk = padded_msk\n",
        "\n",
        "                tile_and_save(img, out_img_dir, base, with_mask=True, msk_np=msk, out_dir_msk=out_msk_dir)\n",
        "            else:\n",
        "                print(f\"Mask bulunamadı: {mp}, sadece görüntü patch'leniyor\")\n",
        "                tile_and_save(img, out_img_dir, base, with_mask=False)\n",
        "        else:\n",
        "            tile_and_save(img, out_img_dir, base, with_mask=False)\n",
        "\n",
        "print(\"\\n Patch çıkarma tamam. Çıktı kökü:\", DST_PATCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q1Ppb_iGxmu"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "\n",
        "DST_PATCH = \"/kaggle/working/LoveDA_Urban_256_subset\"\n",
        "for sp in [\"Train\",\"Val\",\"Test\"]:\n",
        "    n_img = len(glob.glob(os.path.join(DST_PATCH, sp, \"Image\", \"*.png\")))\n",
        "    n_msk = len(glob.glob(os.path.join(DST_PATCH, sp, \"Mask\",  \"*.png\")))\n",
        "    print(f\"{sp}: Image patches={n_img} | Mask patches={n_msk}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, re, time, csv, json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "WORK_DIR = \"/kaggle/working\" if os.path.exists(\"/kaggle/working\") else \".\"\n",
        "def wpath(name): return os.path.join(WORK_DIR, name)\n",
        "\n",
        "DATA_ROOT = wpath(\"LoveDA_Urban_256_subset\")\n",
        "SPLITS = {\n",
        "    \"train\": dict(img=f\"{DATA_ROOT}/Train/Image\", msk=f\"{DATA_ROOT}/Train/Mask\"),\n",
        "    \"val\":   dict(img=f\"{DATA_ROOT}/Val/Image\",   msk=f\"{DATA_ROOT}/Val/Mask\"),\n",
        "    \"test\":  dict(img=f\"{DATA_ROOT}/Test/Image\",  msk=f\"{DATA_ROOT}/Test/Mask\")\n",
        "}\n",
        "\n",
        "NUM_CLASSES  = 7\n",
        "IGNORE_INDEX = 255\n",
        "BATCH_SIZE   = 8\n",
        "NUM_WORKERS  = 2\n",
        "PIN_MEMORY   = True\n",
        "IMG_SIZE     = 256\n",
        "\n",
        "MEAN = (0.485, 0.456, 0.406)\n",
        "STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "id": "_zPNNM9GWTkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tfms = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.03, scale_limit=0.05, rotate_limit=10,\n",
        "                       border_mode=cv2.BORDER_CONSTANT, value=(0,0,0), mask_value=0, p=0.3),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.Normalize(mean=MEAN, std=STD),\n",
        "    ToTensorV2()\n",
        "])\n",
        "val_tfms = A.Compose([\n",
        "    A.Normalize(mean=MEAN, std=STD),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "class SegPatchDataset(Dataset):\n",
        "    def __init__(self, img_dir, msk_dir=None, transform=None, ignore_index=255):\n",
        "        self.imgs = sorted(glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "        self.msk_dir = msk_dir if (msk_dir and os.path.isdir(msk_dir) and glob.glob(os.path.join(msk_dir, \"*.png\"))) else None\n",
        "        self.transform = transform\n",
        "        self.ignore_index = ignore_index\n",
        "        if not self.imgs: raise RuntimeError(f\"Boş klasör: {img_dir}\")\n",
        "\n",
        "        # LUT: 0->255, 1..7->0..6\n",
        "        self.lut = np.full(256, 255, np.uint8)\n",
        "        self.lut[1]=0; self.lut[2]=1; self.lut[3]=2; self.lut[4]=3; self.lut[5]=4; self.lut[6]=5; self.lut[7]=6\n",
        "\n",
        "    def __len__(self): return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        name = os.path.basename(self.imgs[i])\n",
        "        img  = np.array(Image.open(self.imgs[i]).convert(\"RGB\"))\n",
        "\n",
        "        if self.msk_dir:\n",
        "            mp = os.path.join(self.msk_dir, name)\n",
        "            if os.path.isfile(mp):\n",
        "                msk_raw = np.array(Image.open(mp), dtype=np.uint8)\n",
        "                msk = self.lut[msk_raw]\n",
        "            else:\n",
        "                msk = np.full(img.shape[:2], 0, np.uint8)\n",
        "        else:\n",
        "            msk = np.full(img.shape[:2], 0, np.uint8)\n",
        "\n",
        "        if self.transform:\n",
        "            out = self.transform(image=img, mask=msk)\n",
        "            img, msk = out[\"image\"], out[\"mask\"]\n",
        "        else:\n",
        "            img = torch.from_numpy(img).permute(2,0,1).float()/255.0\n",
        "            msk = torch.from_numpy(msk)\n",
        "\n",
        "        return img, msk.long(), name\n",
        "\n",
        "def make_loader(split):\n",
        "    cfg = SPLITS[split]\n",
        "    use_msk = (split!=\"test\") and bool(glob.glob(os.path.join(cfg[\"msk\"], \"*.png\")))\n",
        "    ds = SegPatchDataset(cfg[\"img\"], cfg[\"msk\"] if use_msk else None,\n",
        "                         transform=(train_tfms if split==\"train\" else val_tfms),\n",
        "                         ignore_index=IGNORE_INDEX)\n",
        "    dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=(split==\"train\"),\n",
        "                    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=(split==\"train\"))\n",
        "    return ds, dl\n",
        "\n",
        "train_ds, train_loader = make_loader(\"train\")\n",
        "val_ds,   val_loader   = make_loader(\"val\")\n",
        "test_ds,  test_loader  = make_loader(\"test\")\n",
        "print(\"Train samples:\", len(train_ds), \"Val samples:\", len(val_ds), \"Test samples:\", len(test_ds))\n",
        "xb, yb, nb = next(iter(train_loader)); print(\"Batch:\", xb.shape, yb.shape, nb[:3])\n"
      ],
      "metadata": {
        "id": "XG5Xr1QSWT5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_class_weights(mask_dir, num_classes=NUM_CLASSES, clip_min=0.5, clip_max=5.0):\n",
        "    lut = np.full(256, 255, np.uint8)\n",
        "    lut[1]=0; lut[2]=1; lut[3]=2; lut[4]=3; lut[5]=4; lut[6]=5; lut[7]=6\n",
        "    counts = np.zeros(num_classes, dtype=np.int64)\n",
        "    mask_files = sorted(glob.glob(os.path.join(mask_dir, \"*.png\")))\n",
        "    if not mask_files: return None\n",
        "    for mp in mask_files:\n",
        "        m = np.array(Image.open(mp), dtype=np.uint8)\n",
        "        m = lut[m]\n",
        "        for c in range(num_classes): counts[c] += (m == c).sum()\n",
        "    freq = counts / max(1, counts.sum())\n",
        "    med  = np.median(freq[freq > 0]) if np.any(freq>0) else 1.0\n",
        "    w = (med / np.clip(freq, 1e-12, None)).astype(np.float32)\n",
        "    w = np.clip(w, clip_min, clip_max)\n",
        "    return torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "CLASS_WEIGHTS = compute_class_weights(SPLITS[\"train\"][\"msk\"])\n",
        "if CLASS_WEIGHTS is not None: CLASS_WEIGHTS = CLASS_WEIGHTS.to(device)\n",
        "print(\"Class Weights:\", None if CLASS_WEIGHTS is None else CLASS_WEIGHTS.detach().cpu().numpy().round(3).tolist())\n"
      ],
      "metadata": {
        "id": "n52k2UaBWW7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "@torch.no_grad()\n",
        "def confusion_matrix(pred, target, C, ignore_index=IGNORE_INDEX):\n",
        "    valid = (target != ignore_index)\n",
        "    t = target[valid].view(-1)\n",
        "    p = pred[valid].view(-1)\n",
        "    cm = torch.bincount(t*C + p, minlength=C*C).reshape(C, C).to(torch.long)\n",
        "    return cm\n",
        "\n",
        "def metrics_from_cm(cm):\n",
        "    cm = cm.float()\n",
        "    TP = torch.diag(cm); FP = cm.sum(0) - TP; FN = cm.sum(1) - TP\n",
        "    iou_c  = TP / (TP + FP + FN).clamp(min=1)\n",
        "    dice_c = (2*TP) / (2*TP + FP + FN).clamp(min=1)\n",
        "    acc    = TP.sum() / cm.sum().clamp(min=1)\n",
        "    prec_c = TP / (TP + FP).clamp(min=1)\n",
        "    rec_c  = TP / (TP + FN).clamp(min=1)\n",
        "    f1_c   = 2*prec_c*rec_c / (prec_c + rec_c).clamp(min=1e-12)\n",
        "    return {\n",
        "        \"mean_iou\": iou_c.mean().item(),\n",
        "        \"mean_dice\": dice_c.mean().item(),\n",
        "        \"accuracy\": acc.item(),\n",
        "        \"mean_precision\": prec_c.mean().item(),\n",
        "        \"mean_recall\": rec_c.mean().item(),\n",
        "        \"mean_f1\": f1_c.mean().item(),\n",
        "        \"per_class_iou\": iou_c.detach().cpu().numpy(),\n",
        "        \"per_class_dice\": dice_c.detach().cpu().numpy()\n",
        "    }\n",
        "\n",
        "# Loss\n",
        "def dice_loss_mc(logits, target, ignore_index=IGNORE_INDEX, eps=1e-6):\n",
        "    C = logits.shape[1]\n",
        "    valid = (target != ignore_index)\n",
        "    if valid.sum() == 0: return torch.tensor(0., device=logits.device)\n",
        "    t = target.clone(); t[~valid] = 0\n",
        "    oh = torch.zeros((logits.size(0), C, logits.size(2), logits.size(3)),\n",
        "                     device=logits.device, dtype=torch.float32)\n",
        "    oh.scatter_(1, t.unsqueeze(1), 1.0)\n",
        "    oh = oh * valid.unsqueeze(1)\n",
        "    prob = torch.softmax(logits, dim=1) * valid.unsqueeze(1)\n",
        "    inter = (prob * oh).sum(dim=(0,2,3))\n",
        "    den   = prob.sum(dim=(0,2,3)) + oh.sum(dim=(0,2,3)) + eps\n",
        "    return 1. - (2.*inter / den).mean()\n",
        "\n",
        "def combined_loss(logits, target, class_weights=None):\n",
        "    ce = F.cross_entropy(logits, target, weight=class_weights, ignore_index=IGNORE_INDEX)\n",
        "    dl = dice_loss_mc(logits, target, ignore_index=IGNORE_INDEX)\n",
        "    return 0.7*ce + 0.3*dl\n",
        "\n",
        "# Model\n",
        "model = smp.Unet(encoder_name=\"resnet50\", encoder_weights=\"imagenet\",\n",
        "                 classes=NUM_CLASSES, activation=None).to(device)\n",
        "\n",
        "EPOCHS   = 50\n",
        "LR       = 8e-4\n",
        "WD       = 1e-4\n",
        "PATIENCE = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=LR, epochs=EPOCHS, steps_per_epoch=len(train_loader),\n",
        "                       pct_start=0.1, div_factor=10.0, final_div_factor=100.0)\n",
        "scaler = GradScaler()\n",
        "\n",
        "BEST_CKPT  = wpath(\"best_unet_50epochs.pth\")\n",
        "CSV_HISTORY= wpath(\"unet_training_history.csv\")\n",
        "PLOT_PNG   = wpath(\"unet_training_results.png\")\n",
        "\n",
        "history = {\"epoch\":[], \"train_loss\":[], \"val_loss\":[], \"mIoU\":[], \"Acc\":[], \"Dice\":[], \"F1\":[]}\n",
        "best = {\"epoch\":0, \"mIoU\":-1.0, \"metrics\":None}\n",
        "with open(CSV_HISTORY, \"w\", newline=\"\") as f:\n",
        "    csv.writer(f).writerow([\"epoch\",\"train_loss\",\"val_loss\",\"mIoU\",\"Acc\",\"Dice\",\"F1\"])\n",
        "\n",
        "epochs_no_improve = 0\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    # TRAIN\n",
        "    model.train(); total_loss = 0.0\n",
        "    for xb, yb, _ in tqdm(train_loader, desc=f\"Train {epoch}/{EPOCHS}\", leave=False):\n",
        "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast():\n",
        "            logits = model(xb)\n",
        "            loss = combined_loss(logits, yb, class_weights=CLASS_WEIGHTS)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    train_loss = total_loss / max(1, len(train_loader.dataset))\n",
        "\n",
        "    # VAL\n",
        "    model.eval(); cm_total = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.long, device=device); val_loss=0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, _ in tqdm(val_loader, desc=\"Val\", leave=False):\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            val_loss += combined_loss(logits, yb, class_weights=CLASS_WEIGHTS).item() * xb.size(0)\n",
        "            preds = logits.argmax(1)\n",
        "            cm_total += confusion_matrix(preds, yb, C=NUM_CLASSES, ignore_index=IGNORE_INDEX)\n",
        "    val_loss /= max(1, len(val_loader.dataset))\n",
        "    mets = metrics_from_cm(cm_total)\n",
        "\n",
        "    # LOG\n",
        "    history[\"epoch\"].append(epoch)\n",
        "    for k,v in [(\"train_loss\",train_loss),(\"val_loss\",val_loss),\n",
        "                (\"mIoU\",mets[\"mean_iou\"]),(\"Acc\",mets[\"accuracy\"]),\n",
        "                (\"Dice\",mets[\"mean_dice\"]),(\"F1\",mets[\"mean_f1\"])]:\n",
        "        history[k].append(v)\n",
        "    with open(CSV_HISTORY, \"a\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow([epoch, f\"{train_loss:.6f}\", f\"{val_loss:.6f}\",\n",
        "                                f\"{mets['mean_iou']:.6f}\", f\"{mets['accuracy']:.6f}\",\n",
        "                                f\"{mets['mean_dice']:.6f}\", f\"{mets['mean_f1']:.6f}\"])\n",
        "\n",
        "    print(f\"[{epoch:03d}] Train:{train_loss:.4f} | Val:{val_loss:.4f} | \"\n",
        "          f\"mIoU:{mets['mean_iou']:.3f} Dice:{mets['mean_dice']:.3f} Acc:{mets['accuracy']:.3f} F1:{mets['mean_f1']:.3f}\")\n",
        "\n",
        "    # BEST SAVE (mIoU) + Early Stop\n",
        "    if mets[\"mean_iou\"] > best[\"mIoU\"]:\n",
        "        best.update({\"epoch\":epoch, \"mIoU\":mets[\"mean_iou\"], \"metrics\":mets})\n",
        "        torch.save({\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"metrics\": mets,\n",
        "            \"history\": history,\n",
        "            \"config\": {\"num_classes\": NUM_CLASSES, \"ignore_index\": IGNORE_INDEX,\n",
        "                       \"img_size\": IMG_SIZE, \"mean\": MEAN, \"std\": STD}\n",
        "        }, BEST_CKPT)\n",
        "        print(f\" Best updated: mIoU={mets['mean_iou']:.4f} → {BEST_CKPT}\")\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(f\"Early stopping @ {epoch}. Best mIoU={best['mIoU']:.4f} (epoch {best['epoch']})\")\n",
        "            break\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\")\n",
        "plt.plot(history[\"epoch\"], history[\"val_loss\"],   label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.title(\"UNet Training Loss\")\n",
        "plt.tight_layout(); plt.savefig(PLOT_PNG); plt.close()\n",
        "\n",
        "print(\"Eğitim tamam. Best epoch:\", best[\"epoch\"], \"mIoU:\", f\"{best['mIoU']:.4f}\")\n",
        "print(\"Saved:\", BEST_CKPT, \"\\nLogs:\", CSV_HISTORY, \"\\nPlots:\", PLOT_PNG)\n"
      ],
      "metadata": {
        "id": "Uf7vc-vhWfS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv, numpy as np, torch\n",
        "from tqdm import tqdm\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "CKPT_PATH = wpath(\"best_unet_50epochs.pth\")\n",
        "\n",
        "def load_ckpt_safe(path):\n",
        "    try:\n",
        "        from torch.serialization import add_safe_globals\n",
        "        import numpy as np\n",
        "        add_safe_globals([np.core.multiarray._reconstruct])\n",
        "        ckpt = torch.load(path, map_location=\"cpu\", weights_only=True)\n",
        "        if isinstance(ckpt, dict) and (\"model_state_dict\" in ckpt or \"state_dict\" in ckpt):\n",
        "            state = ckpt.get(\"model_state_dict\", ckpt.get(\"state_dict\"))\n",
        "            return state, ckpt\n",
        "\n",
        "        if isinstance(ckpt, dict):\n",
        "            return ckpt, {\"_raw\": \"state_dict_only\"}\n",
        "    except Exception as e:\n",
        "        print(f\"[info] Safe load (weights_only=True) olmadı: {e}\")\n",
        "\n",
        "    ckpt = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
        "    if isinstance(ckpt, dict) and (\"model_state_dict\" in ckpt or \"state_dict\" in ckpt):\n",
        "        state = ckpt.get(\"model_state_dict\", ckpt.get(\"state_dict\"))\n",
        "        return state, ckpt\n",
        "    return ckpt, {\"_raw\": \"state_dict_only\"}\n",
        "\n",
        "state_dict, meta = load_ckpt_safe(CKPT_PATH)\n",
        "\n",
        "model_eval = smp.Unet(encoder_name=\"resnet50\", encoder_weights=None,\n",
        "                      classes=NUM_CLASSES, activation=None).to(device).eval()\n",
        "model_eval.load_state_dict(state_dict)\n",
        "\n",
        "@torch.no_grad()\n",
        "def confusion_matrix(pred, target, C, ignore_index=IGNORE_INDEX):\n",
        "    valid = (target != ignore_index)\n",
        "    t = target[valid].view(-1); p = pred[valid].view(-1)\n",
        "    return torch.bincount(t*C + p, minlength=C*C).reshape(C, C).to(torch.long)\n",
        "\n",
        "def metrics_from_cm(cm):\n",
        "    cm = cm.float()\n",
        "    TP = torch.diag(cm); FP = cm.sum(0) - TP; FN = cm.sum(1) - TP\n",
        "    iou_c  = TP / (TP + FP + FN).clamp(min=1)\n",
        "    dice_c = (2*TP) / (2*TP + FP + FN).clamp(min=1)\n",
        "    acc    = TP.sum() / cm.sum().clamp(min=1)\n",
        "    prec_c = TP / (TP + FP).clamp(min=1)\n",
        "    rec_c  = TP / (TP + FN).clamp(min=1)\n",
        "    f1_c   = 2*prec_c*rec_c / (prec_c + rec_c).clamp(min=1e-12)\n",
        "    return {\n",
        "        \"mean_iou\": iou_c.mean().item(),\n",
        "        \"mean_dice\": dice_c.mean().item(),\n",
        "        \"accuracy\": acc.item(),\n",
        "        \"mean_precision\": prec_c.mean().item(),\n",
        "        \"mean_recall\": rec_c.mean().item(),\n",
        "        \"mean_f1\": f1_c.mean().item(),\n",
        "        \"per_class_iou\": iou_c.detach().cpu().numpy(),\n",
        "        \"per_class_dice\": dice_c.detach().cpu().numpy()\n",
        "    }\n",
        "\n",
        "cm_total = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.long, device=device)\n",
        "with torch.no_grad():\n",
        "    for xb, yb, _ in tqdm(val_loader, desc=\"Eval/CSV\"):\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        preds = model_eval(xb).argmax(1)\n",
        "        cm_total += confusion_matrix(preds, yb, C=NUM_CLASSES, ignore_index=IGNORE_INDEX)\n",
        "\n",
        "mets = metrics_from_cm(cm_total)\n",
        "print(\"VAL overall:\",\n",
        "      {k: round(v,4) for k,v in mets.items() if isinstance(v, float)})\n",
        "\n",
        "CSV_OVERALL = wpath(\"unet_50epochs_metrics_overall.csv\")\n",
        "CSV_PERCLS  = wpath(\"unet_50epochs_metrics_per_class.csv\")\n",
        "CLASS_NAMES = ['Background','Building','Road','Water','Barren','Forest','Agriculture']\n",
        "\n",
        "with open(CSV_OVERALL, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"metric\",\"value\"])\n",
        "    for k in [\"mean_iou\",\"mean_dice\",\"accuracy\",\"mean_precision\",\"mean_recall\",\"mean_f1\"]:\n",
        "        w.writerow([k, f\"{mets[k]:.6f}\"])\n",
        "\n",
        "with open(CSV_PERCLS, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"class_id\",\"class_name\",\"IoU\",\"Dice\"])\n",
        "    for i, name in enumerate(CLASS_NAMES):\n",
        "        w.writerow([i, name, f\"{mets['per_class_iou'][i]:.6f}\", f\"{mets['per_class_dice'][i]:.6f}\"])\n",
        "\n",
        "print(\"Saved CSVs:\", CSV_OVERALL, CSV_PERCLS)\n"
      ],
      "metadata": {
        "id": "K-WZXyelWs5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "COLOR_MAP = {\n",
        "    0: (255, 255, 255),  # Background (beyaz)\n",
        "    1: (255,   0,   0),  # Building (kırmızı)\n",
        "    2: (255, 255,   0),  # Road (sarı)\n",
        "    3: (  0,   0, 255),  # Water (mavi)\n",
        "    4: (159, 129, 183),  # Barren (mor)\n",
        "    5: (  0, 255,   0),  # Forest (yeşil)\n",
        "    6: (255, 195, 128)   # Agricultural (turuncu)\n",
        "}\n",
        "PALETTE = np.array([COLOR_MAP[i] for i in range(0, 7)], dtype=np.uint8)\n",
        "\n",
        "def colorize(mask_hw: np.ndarray) -> np.ndarray:\n",
        "    rgb = np.zeros((mask_hw.shape[0], mask_hw.shape[1], 3), dtype=np.uint8)\n",
        "    valid = (mask_hw >= 0) & (mask_hw < len(PALETTE))\n",
        "    rgb[valid] = PALETTE[mask_hw[valid]]\n",
        "    return rgb\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_with_tta(x, model_for_infer):\n",
        "    logits = model_for_infer(x)\n",
        "    logits_flip = model_for_infer(torch.flip(x, dims=[-1]))\n",
        "    logits_flip = torch.flip(logits_flip, dims=[-1])\n",
        "    return 0.5 * (logits + logits_flip)\n",
        "\n",
        "SAVE_VAL  = wpath(\"unet_preds_val\");  os.makedirs(SAVE_VAL,  exist_ok=True)\n",
        "SAVE_TEST = wpath(\"unet_preds_test\"); os.makedirs(SAVE_TEST, exist_ok=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_and_save(dl, save_dir, desc):\n",
        "    for xb, _, names in tqdm(dl, desc=desc):\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        logits = predict_with_tta(xb, model_eval)\n",
        "        preds  = logits.argmax(1).cpu().numpy().astype(np.uint8)\n",
        "        for p, name in zip(preds, names):\n",
        "            Image.fromarray(colorize(p)).save(os.path.join(save_dir, name))\n",
        "\n",
        "predict_and_save(val_loader,  SAVE_VAL,  \"VAL predict→PNG (B palette, TTA)\")\n",
        "predict_and_save(test_loader, SAVE_TEST, \"TEST predict→PNG (B palette, TTA)\")\n",
        "print(\"VAL preds:\", SAVE_VAL, \"| TEST preds:\", SAVE_TEST)\n",
        "\n",
        "TILE = IMG_SIZE\n",
        "VAL_IMG_DIR = SPLITS[\"val\"][\"img\"]\n",
        "VAL_MSK_DIR = SPLITS[\"val\"][\"msk\"]\n",
        "PRED_DIR    = SAVE_VAL\n",
        "\n",
        "rx = re.compile(r\"^(?P<base>.+)_r(?P<r>\\d+)_c(?P<c>\\d+)\\.png$\")\n",
        "LUT = np.full(256, 255, np.uint8); LUT[1]=0; LUT[2]=1; LUT[3]=2; LUT[4]=3; LUT[5]=4; LUT[6]=5; LUT[7]=6\n",
        "\n",
        "def draw_grid(img, tile=TILE, lw=1):\n",
        "    out = img.copy()\n",
        "    for y in range(tile, img.shape[0], tile): out[y-lw:y+lw, :] = 255\n",
        "    for x in range(tile, img.shape[1], tile): out[:, x-lw:x+lw] = 255\n",
        "    return out\n",
        "\n",
        "def find_base_ids(img_dir):\n",
        "    files = sorted(glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "    bases = {}\n",
        "    for fp in files:\n",
        "        m = rx.match(os.path.basename(fp))\n",
        "        if not m: continue\n",
        "        b = m.group(\"base\"); r = int(m.group(\"r\")); c = int(m.group(\"c\"))\n",
        "        R, C, cnt = bases.get(b, (0,0,0))\n",
        "        bases[b] = (max(R, r+1), max(C, c+1), cnt+1)\n",
        "    return [b for b,_ in sorted(bases.items(), key=lambda kv: -kv[1][2])]\n",
        "\n",
        "def reconstruct_full(img_dir, base):\n",
        "    pats = sorted(glob.glob(os.path.join(img_dir, f\"{base}_r*_c*.png\")))\n",
        "    assert pats, f\"Patch yok: {base}\"\n",
        "    rs, cs = [], []\n",
        "    for p in pats:\n",
        "        m = rx.match(os.path.basename(p)); rs.append(int(m.group(\"r\"))); cs.append(int(m.group(\"c\")))\n",
        "    R, C = max(rs)+1, max(cs)+1\n",
        "    H, W = R*TILE, C*TILE\n",
        "    full_img = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for p in pats:\n",
        "        m = rx.match(os.path.basename(p)); r, c = int(m.group(\"r\")), int(m.group(\"c\"))\n",
        "        img = np.array(Image.open(p).convert(\"RGB\"))\n",
        "        full_img[r*TILE:(r+1)*TILE, c*TILE:(c+1)*TILE] = img\n",
        "    return full_img\n",
        "\n",
        "base_ids = find_base_ids(VAL_IMG_DIR)\n",
        "assert base_ids, \"Val/Image içinde patch bulunamadı.\"\n",
        "BASE = base_ids[1]\n",
        "\n",
        "full_img      = reconstruct_full(VAL_IMG_DIR, BASE)\n",
        "full_img_grid = draw_grid(full_img, tile=TILE, lw=1)\n",
        "\n",
        "pred_patch_files = sorted(glob.glob(os.path.join(PRED_DIR, f\"{BASE}_r*_c*.png\")))\n",
        "rs, cs = [], []\n",
        "for p in pred_patch_files:\n",
        "    m = rx.match(os.path.basename(p)); rs.append(int(m.group(\"r\"))); cs.append(int(m.group(\"c\")))\n",
        "R, C = max(rs)+1, max(cs)+1\n",
        "H, W = R*TILE, C*TILE\n",
        "full_pred_rgb = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "for p in pred_patch_files:\n",
        "    m = rx.match(os.path.basename(p)); r, c = int(m.group(\"r\")), int(m.group(\"c\"))\n",
        "    rgb = np.array(Image.open(p).convert(\"RGB\"))\n",
        "    full_pred_rgb[r*TILE:(r+1)*TILE, c*TILE:(c+1)*TILE] = rgb\n",
        "\n",
        "full_gt_rgb = None\n",
        "if VAL_MSK_DIR and os.path.isdir(VAL_MSK_DIR):\n",
        "    gt_patch_files = sorted(glob.glob(os.path.join(VAL_MSK_DIR, f\"{BASE}_r*_c*.png\")))\n",
        "    if gt_patch_files:\n",
        "        rs, cs = [], []\n",
        "        for p in gt_patch_files:\n",
        "            m = rx.match(os.path.basename(p)); rs.append(int(m.group(\"r\"))); cs.append(int(m.group(\"c\")))\n",
        "        Rg, Cg = max(rs)+1, max(cs)+1\n",
        "        Hg, Wg = Rg*TILE, Cg*TILE\n",
        "        full_gt = np.zeros((Hg, Wg), dtype=np.uint8)\n",
        "\n",
        "        for p in gt_patch_files:\n",
        "            m = rx.match(os.path.basename(p)); r, c = int(m.group(\"r\")), int(m.group(\"c\"))\n",
        "            msk_raw = np.array(Image.open(p), dtype=np.uint8)\n",
        "            if msk_raw.max() > 6:\n",
        "                msk = LUT[msk_raw]\n",
        "            else:\n",
        "                msk = msk_raw\n",
        "            full_gt[r*TILE:(r+1)*TILE, c*TILE:(c+1)*TILE] = msk\n",
        "\n",
        "        full_gt_rgb = colorize(full_gt)\n",
        "\n",
        "if full_gt_rgb is not None:\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(1,4,1); plt.imshow(full_img);      plt.title(f\"Image (base={BASE})\"); plt.axis('off')\n",
        "    plt.subplot(1,4,2); plt.imshow(full_img_grid); plt.title(\"Patch Grid\");          plt.axis('off')\n",
        "    plt.subplot(1,4,3); plt.imshow(full_gt_rgb);   plt.title(\"Ground Truth\");        plt.axis('off')\n",
        "    plt.subplot(1,4,4); plt.imshow(full_pred_rgb); plt.title(\"U-Net Prediction\");    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    OUT_FULL = wpath(f\"vis_full_grid_pred_{BASE}_withGT.png\")\n",
        "else:\n",
        "    plt.figure(figsize=(16,5))\n",
        "    plt.subplot(1,3,1); plt.imshow(full_img);      plt.title(f\"Image (base={BASE})\"); plt.axis('off')\n",
        "    plt.subplot(1,3,2); plt.imshow(full_img_grid); plt.title(\"Patch Grid\");          plt.axis('off')\n",
        "    plt.subplot(1,3,3); plt.imshow(full_pred_rgb); plt.title(\"U-Net Prediction\");    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    OUT_FULL = wpath(f\"vis_full_grid_pred_{BASE}.png\")\n",
        "\n",
        "plt.savefig(OUT_FULL, dpi=150); plt.close()\n",
        "print(\" Kaydedildi:\", OUT_FULL)\n"
      ],
      "metadata": {
        "id": "yTY1Smc9XYxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DeepLabV3+\n",
        "import torch, csv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "#Metrikler\n",
        "@torch.no_grad()\n",
        "def confusion_matrix(pred, target, C, ignore_index=IGNORE_INDEX):\n",
        "    valid = (target != ignore_index)\n",
        "    t = target[valid].view(-1); p = pred[valid].view(-1)\n",
        "    return torch.bincount(t*C + p, minlength=C*C).reshape(C, C).to(torch.long)\n",
        "\n",
        "def metrics_from_cm(cm):\n",
        "    cm = cm.float()\n",
        "    TP = torch.diag(cm); FP = cm.sum(0) - TP; FN = cm.sum(1) - TP\n",
        "    iou_c  = TP / (TP + FP + FN).clamp(min=1)\n",
        "    dice_c = (2*TP) / (2*TP + FP + FN).clamp(min=1)\n",
        "    acc    = TP.sum() / cm.sum().clamp(min=1)\n",
        "    prec_c = TP / (TP + FP).clamp(min=1)\n",
        "    rec_c  = TP / (TP + FN).clamp(min=1)\n",
        "    f1_c   = 2*prec_c*rec_c / (prec_c + rec_c).clamp(min=1e-12)\n",
        "    return {\n",
        "        \"mean_iou\": iou_c.mean().item(),\n",
        "        \"mean_dice\": dice_c.mean().item(),\n",
        "        \"accuracy\": acc.item(),\n",
        "        \"mean_precision\": prec_c.mean().item(),\n",
        "        \"mean_recall\": rec_c.mean().item(),\n",
        "        \"mean_f1\": f1_c.mean().item(),\n",
        "        \"per_class_iou\": iou_c.detach().cpu().numpy(),\n",
        "        \"per_class_dice\": dice_c.detach().cpu().numpy()\n",
        "    }\n",
        "\n",
        "#Loss\n",
        "def dice_loss_mc(logits, target, ignore_index=IGNORE_INDEX, eps=1e-6):\n",
        "    C = logits.shape[1]\n",
        "    valid = (target != ignore_index)\n",
        "    if valid.sum() == 0: return torch.tensor(0., device=logits.device)\n",
        "    t = target.clone(); t[~valid] = 0\n",
        "    oh = torch.zeros((logits.size(0), C, logits.size(2), logits.size(3)),\n",
        "                     device=logits.device, dtype=torch.float32)\n",
        "    oh.scatter_(1, t.unsqueeze(1), 1.0)\n",
        "    oh = oh * valid.unsqueeze(1)\n",
        "    prob = torch.softmax(logits, dim=1) * valid.unsqueeze(1)\n",
        "    inter = (prob * oh).sum(dim=(0,2,3))\n",
        "    den   = prob.sum(dim=(0,2,3)) + oh.sum(dim=(0,2,3)) + eps\n",
        "    return 1. - (2.*inter / den).mean()\n",
        "\n",
        "def combined_loss(logits, target, class_weights=None):\n",
        "    ce = F.cross_entropy(logits, target, weight=class_weights, ignore_index=IGNORE_INDEX)\n",
        "    dl = dice_loss_mc(logits, target, ignore_index=IGNORE_INDEX)\n",
        "    return 0.7*ce + 0.3*dl\n",
        "\n",
        "# Model\n",
        "model = smp.DeepLabV3Plus(\n",
        "    encoder_name=\"resnet50\", encoder_weights=\"imagenet\",\n",
        "    classes=NUM_CLASSES, activation=None\n",
        ").to(device)\n",
        "\n",
        "\n",
        "EPOCHS   = 50\n",
        "LR       = 8e-4\n",
        "WD       = 1e-4\n",
        "PATIENCE = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=LR, epochs=EPOCHS, steps_per_epoch=len(train_loader),\n",
        "                       pct_start=0.1, div_factor=10.0, final_div_factor=100.0)\n",
        "scaler = GradScaler()\n",
        "\n",
        "BEST_CKPT  = wpath(\"best_deeplabv3plus_50epochs.pth\")\n",
        "CSV_HISTORY= wpath(\"deeplabv3plus_training_history.csv\")\n",
        "PLOT_PNG   = wpath(\"deeplabv3plus_training_results.png\")\n",
        "\n",
        "\n",
        "history = {\"epoch\":[], \"train_loss\":[], \"val_loss\":[], \"mIoU\":[], \"Acc\":[], \"Dice\":[], \"F1\":[]}\n",
        "best = {\"epoch\":0, \"mIoU\":-1.0, \"metrics\":None}\n",
        "with open(CSV_HISTORY, \"w\", newline=\"\") as f:\n",
        "    csv.writer(f).writerow([\"epoch\",\"train_loss\",\"val_loss\",\"mIoU\",\"Acc\",\"Dice\",\"F1\"])\n",
        "\n",
        "epochs_no_improve = 0\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    # TRAIN\n",
        "    model.train(); total_loss = 0.0\n",
        "    for xb, yb, _ in tqdm(train_loader, desc=f\"Train {epoch}/{EPOCHS}\", leave=False):\n",
        "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast():\n",
        "            logits = model(xb)\n",
        "            loss = combined_loss(logits, yb, class_weights=CLASS_WEIGHTS)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    train_loss = total_loss / max(1, len(train_loader.dataset))\n",
        "\n",
        "    # VAL\n",
        "    model.eval(); cm_total = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.long, device=device); val_loss=0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, _ in tqdm(val_loader, desc=\"Val\", leave=False):\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            val_loss += combined_loss(logits, yb, class_weights=CLASS_WEIGHTS).item() * xb.size(0)\n",
        "            preds = logits.argmax(1)\n",
        "            cm_total += confusion_matrix(preds, yb, C=NUM_CLASSES, ignore_index=IGNORE_INDEX)\n",
        "    val_loss /= max(1, len(val_loader.dataset))\n",
        "    mets = metrics_from_cm(cm_total)\n",
        "\n",
        "    # LOG\n",
        "    history[\"epoch\"].append(epoch)\n",
        "    for k,v in [(\"train_loss\",train_loss),(\"val_loss\",val_loss),\n",
        "                (\"mIoU\",mets[\"mean_iou\"]),(\"Acc\",mets[\"accuracy\"]),\n",
        "                (\"Dice\",mets[\"mean_dice\"]),(\"F1\",mets[\"mean_f1\"])]:\n",
        "        history[k].append(v)\n",
        "    with open(CSV_HISTORY, \"a\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow([epoch, f\"{train_loss:.6f}\", f\"{val_loss:.6f}\",\n",
        "                                f\"{mets['mean_iou']:.6f}\", f\"{mets['accuracy']:.6f}\",\n",
        "                                f\"{mets['mean_dice']:.6f}\", f\"{mets['mean_f1']:.6f}\"])\n",
        "\n",
        "    print(f\"[{epoch:03d}] Train:{train_loss:.4f} | Val:{val_loss:.4f} | \"\n",
        "          f\"mIoU:{mets['mean_iou']:.3f} Dice:{mets['mean_dice']:.3f} Acc:{mets['accuracy']:.3f} F1:{mets['mean_f1']:.3f}\")\n",
        "\n",
        "    # BEST SAVE (mIoU) + Early Stop\n",
        "    if mets[\"mean_iou\"] > best[\"mIoU\"]:\n",
        "        best.update({\"epoch\":epoch, \"mIoU\":mets[\"mean_iou\"], \"metrics\":mets})\n",
        "        torch.save({\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"metrics\": mets,\n",
        "            \"history\": history,\n",
        "            \"config\": {\"num_classes\": NUM_CLASSES, \"ignore_index\": IGNORE_INDEX,\n",
        "                       \"img_size\": IMG_SIZE, \"mean\": MEAN, \"std\": STD}\n",
        "        }, BEST_CKPT)\n",
        "        print(f\"Best updated: mIoU={mets['mean_iou']:.4f} → {BEST_CKPT}\")\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(f\"Early stopping @ {epoch}. Best mIoU={best['mIoU']:.4f} (epoch {best['epoch']})\")\n",
        "            break\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\")\n",
        "plt.plot(history[\"epoch\"], history[\"val_loss\"],   label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.title(\"DeepLabV3+ Training Loss\")\n",
        "plt.tight_layout(); plt.savefig(PLOT_PNG); plt.close()\n",
        "\n",
        "print(\" Eğitim tamam. Best epoch:\", best[\"epoch\"], \"mIoU:\", f\"{best['mIoU']:.4f}\")\n",
        "print(\"Saved:\", BEST_CKPT, \"\\nLogs:\", CSV_HISTORY, \"\\nPlots:\", PLOT_PNG)\n"
      ],
      "metadata": {
        "id": "CP8yVkX-kLNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    cm_total = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.long, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, _ in tqdm(loader, desc=\"Validation\"):\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            preds = logits.argmax(1)\n",
        "            cm_total += confusion_matrix(preds, yb, C=NUM_CLASSES, ignore_index=IGNORE_INDEX)\n",
        "\n",
        "    return metrics_from_cm(cm_total)\n",
        "\n",
        "mets = evaluate(model, val_loader, device)\n",
        "\n",
        "print(f\" Overall Accuracy: {mets['accuracy']:.4f}\")\n",
        "print(f\" Mean IoU: {mets['mean_iou']:.4f}\")\n",
        "print(f\" Mean Dice: {mets['mean_dice']:.4f}\")\n",
        "print(f\" Mean Precision: {mets['mean_precision']:.4f}\")\n",
        "print(f\" Mean Recall: {mets['mean_recall']:.4f}\")\n",
        "print(f\" Mean F1-Score: {mets['mean_f1']:.4f}\")\n",
        "\n",
        "for i, name in enumerate(CLASS_NAMES):\n",
        "    print(f\"{name:>11} {mets['per_class_iou'][i]:.3f} {mets['per_class_dice'][i]:.3f} \"\n",
        "          f\"{mets['per_class_precision'][i]:.3f} {mets['per_class_recall'][i]:.3f} \"\n",
        "          f\"{mets['per_class_f1'][i]:.3f}\")\n",
        "\n",
        "CSV_OVERALL = wpath(\"deeplabv3plus_metrics_overall.csv\")\n",
        "CSV_PERCLS  = wpath(\"deeplabv3plus_metrics_per_class.csv\")\n",
        "\n",
        "with open(CSV_OVERALL, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"metric\",\"value\"])\n",
        "    for k in [\"mean_iou\",\"mean_dice\",\"accuracy\",\"mean_precision\",\"mean_recall\",\"mean_f1\"]:\n",
        "        w.writerow([k, f\"{mets[k]:.6f}\"])\n",
        "\n",
        "with open(CSV_PERCLS, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"class_id\",\"class_name\",\"IoU\",\"Dice\",\"Precision\",\"Recall\",\"F1\"])\n",
        "    for i, name in enumerate(CLASS_NAMES):\n",
        "        w.writerow([\n",
        "            i, name,\n",
        "            f\"{mets['per_class_iou'][i]:.6f}\",\n",
        "            f\"{mets['per_class_dice'][i]:.6f}\",\n",
        "            f\"{mets['per_class_precision'][i]:.6f}\",\n",
        "            f\"{mets['per_class_recall'][i]:.6f}\",\n",
        "            f\"{mets['per_class_f1'][i]:.6f}\"\n",
        "        ])\n",
        "\n",
        "print(\"\\n CSV dosyaları kaydedildi:\", CSV_OVERALL, \"ve\", CSV_PERCLS)\n"
      ],
      "metadata": {
        "id": "coeBvc1ylcQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, re, csv, time\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import segmentation_models_pytorch as smp\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def find_deeplab_ckpt():\n",
        "    candidates = []\n",
        "    for base in [wpath(\"\"), \"/kaggle/working\", \".\"]:\n",
        "        try:\n",
        "            for p in glob.glob(os.path.join(base, \"*.pth\")):\n",
        "                name = os.path.basename(p).lower()\n",
        "                if \"deeplab\" in name or \"v3\" in name:\n",
        "                    candidates.append(p)\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not candidates:\n",
        "        raise FileNotFoundError(\"DeepLabV3+ checkpoint bulunamadı.\")\n",
        "    candidates.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n",
        "    return candidates[0]\n",
        "\n",
        "CKPT_PATH = wpath(\"best_deeplabv3plus_50epochs.pth\")\n",
        "if not os.path.isfile(CKPT_PATH):\n",
        "    CKPT_PATH = find_deeplab_ckpt()\n",
        "print(\" Kullanılacak checkpoint:\", CKPT_PATH)\n",
        "\n",
        "def load_ckpt_safe(path):\n",
        "    try:\n",
        "        from torch.serialization import add_safe_globals\n",
        "        import numpy as np\n",
        "        add_safe_globals([np.core.multiarray._reconstruct])\n",
        "        ckpt = torch.load(path, map_location=\"cpu\", weights_only=True)\n",
        "        if isinstance(ckpt, dict) and (\"model_state_dict\" in ckpt or \"state_dict\" in ckpt):\n",
        "            return ckpt.get(\"model_state_dict\", ckpt.get(\"state_dict\")), ckpt\n",
        "        if isinstance(ckpt, dict):\n",
        "            return ckpt, {\"_raw\": \"state_dict_only\"}\n",
        "    except Exception as e:\n",
        "        print(f\"[info] Safe load (weights_only=True) olmadı: {e}\")\n",
        "    ckpt = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
        "    if isinstance(ckpt, dict) and (\"model_state_dict\" in ckpt or \"state_dict\" in ckpt):\n",
        "        return ckpt.get(\"model_state_dict\", ckpt.get(\"state_dict\")), ckpt\n",
        "    return ckpt, {\"_raw\": \"state_dict_only\"}\n",
        "\n",
        "state_dict, meta = load_ckpt_safe(CKPT_PATH)\n",
        "\n",
        "model_eval = smp.DeepLabV3Plus(\n",
        "    encoder_name=\"resnet50\",\n",
        "    encoder_weights=None,\n",
        "    classes=NUM_CLASSES,\n",
        "    activation=None\n",
        ").to(device).eval()\n",
        "model_eval.load_state_dict(state_dict)\n",
        "\n",
        "COLOR_MAP = {\n",
        "    0: (255, 255, 255),  # Background\n",
        "    1: (255,   0,   0),  # Building\n",
        "    2: (255, 255,   0),  # Road\n",
        "    3: (  0,   0, 255),  # Water\n",
        "    4: (159, 129, 183),  # Barren\n",
        "    5: (  0, 255,   0),  # Forest\n",
        "    6: (255, 195, 128)   # Agricultural\n",
        "}\n",
        "PALETTE = np.array([COLOR_MAP[i] for i in range(0, 7)], dtype=np.uint8)\n",
        "\n",
        "def colorize(mask_hw: np.ndarray) -> np.ndarray:\n",
        "    rgb = np.zeros((mask_hw.shape[0], mask_hw.shape[1], 3), dtype=np.uint8)\n",
        "    valid = (mask_hw >= 0) & (mask_hw < len(PALETTE))\n",
        "    rgb[valid] = PALETTE[mask_hw[valid]]\n",
        "    return rgb\n",
        "\n",
        "SAVE_VAL  = wpath(\"deeplab_preds_val\");  os.makedirs(SAVE_VAL,  exist_ok=True)\n",
        "\n",
        "TILE = IMG_SIZE\n",
        "VAL_IMG_DIR = SPLITS[\"val\"][\"img\"]\n",
        "PRED_DIR    = SAVE_VAL\n",
        "\n",
        "rx = re.compile(r\"^(?P<base>.+)_r(?P<r>\\d+)_c(?P<c>\\d+)\\.png$\")\n",
        "\n",
        "def draw_grid(img, tile=TILE, lw=1):\n",
        "    out = img.copy()\n",
        "    for y in range(tile, img.shape[0], tile): out[y-lw:y+lw, :] = 255\n",
        "    for x in range(tile, img.shape[1], tile): out[:, x-lw:x+lw] = 255\n",
        "    return out\n",
        "\n",
        "def find_base_ids(img_dir):\n",
        "    files = sorted(glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "    bases = {}\n",
        "    for fp in files:\n",
        "        m = rx.match(os.path.basename(fp))\n",
        "        if not m: continue\n",
        "        b = m.group(\"base\"); r = int(m.group(\"r\")); c = int(m.group(\"c\"))\n",
        "        R, C, cnt = bases.get(b, (0,0,0))\n",
        "        bases[b] = (max(R, r+1), max(C, c+1), cnt+1)\n",
        "    return [b for b,_ in sorted(bases.items(), key=lambda kv: -kv[1][2])]\n",
        "\n",
        "def reconstruct_full(img_dir, base):\n",
        "    pats = sorted(glob.glob(os.path.join(img_dir, f\"{base}_r*_c*.png\")))\n",
        "    assert pats, f\"Patch yok: {base}\"\n",
        "    rs, cs = [], []\n",
        "    for p in pats:\n",
        "        m = rx.match(os.path.basename(p)); rs.append(int(m.group(\"r\"))); cs.append(int(m.group(\"c\")))\n",
        "    R, C = max(rs)+1, max(cs)+1\n",
        "    H, W = R*TILE, C*TILE\n",
        "    full_img = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for p in pats:\n",
        "        m = rx.match(os.path.basename(p)); r, c = int(m.group(\"r\")), int(m.group(\"c\"))\n",
        "        img = np.array(Image.open(p).convert(\"RGB\"))\n",
        "        full_img[r*TILE:(r+1)*TILE, c*TILE:(c+1)*TILE] = img\n",
        "    return full_img\n",
        "\n",
        "BASE = \"3515\"\n",
        "base_ids = find_base_ids(VAL_IMG_DIR)\n",
        "if BASE not in base_ids and len(base_ids)>0:\n",
        "    BASE = base_ids[0]\n",
        "print(\"Seçilen base:\", BASE)\n",
        "\n",
        "full_img      = reconstruct_full(VAL_IMG_DIR, BASE)\n",
        "full_img_grid = draw_grid(full_img, tile=TILE, lw=1)\n",
        "\n",
        "\n",
        "pred_patch_files = sorted(glob.glob(os.path.join(PRED_DIR, f\"{BASE}_r*_c*.png\")))\n",
        "rs, cs = [], []\n",
        "for p in pred_patch_files:\n",
        "    m = rx.match(os.path.basename(p)); rs.append(int(m.group(\"r\"))); cs.append(int(m.group(\"c\")))\n",
        "R, C = max(rs)+1, max(cs)+1\n",
        "H, W = R*TILE, C*TILE\n",
        "full_pred_rgb = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "for p in pred_patch_files:\n",
        "    m = rx.match(os.path.basename(p)); r, c = int(m.group(\"r\")), int(m.group(\"c\"))\n",
        "    rgb = np.array(Image.open(p).convert(\"RGB\"))\n",
        "    full_pred_rgb[r*TILE:(r+1)*TILE, c*TILE:(c+1)*TILE] = rgb\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.subplot(1,3,1); plt.imshow(full_img);      plt.title(f\"Image (base={BASE})\"); plt.axis('off')\n",
        "plt.subplot(1,3,2); plt.imshow(full_img_grid); plt.title(\"Patch Grid\");           plt.axis('off')\n",
        "plt.subplot(1,3,3); plt.imshow(full_pred_rgb); plt.title(\"DeepLabV3+ Prediction\"); plt.axis('off')\n",
        "plt.tight_layout()\n",
        "OUT_FULL = wpath(f\"vis_full_grid_pred_{BASE}_deeplab.png\")\n",
        "\n",
        "plt.savefig(OUT_FULL, dpi=150); plt.close()\n",
        "print(\"Kaydedildi:\", OUT_FULL)\n"
      ],
      "metadata": {
        "id": "-IRLZhBGzNji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FCN\n",
        "import os, time, csv, glob, re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "if 'wpath' not in globals():\n",
        "    def wpath(name): return os.path.join(\"/kaggle/working\", name)\n",
        "\n",
        "if 'CLASS_WEIGHTS' not in globals() or CLASS_WEIGHTS is None:\n",
        "    CLASS_WEIGHTS = torch.ones(NUM_CLASSES, dtype=torch.float32, device=device)\n",
        "\n",
        "def dice_loss_mc(logits, target, ignore_index=255, eps=1e-6):\n",
        "    C = logits.shape[1]\n",
        "    valid = (target != ignore_index)\n",
        "    if valid.sum() == 0:\n",
        "        return torch.tensor(0., device=logits.device)\n",
        "\n",
        "    t = target.clone(); t[~valid] = 0\n",
        "    pred = F.softmax(logits, dim=1)\n",
        "    pred = pred.permute(0,2,3,1).reshape(-1, C)\n",
        "    tgt1h = F.one_hot(t.reshape(-1), C).float().to(logits.device)\n",
        "    tgt1h[~valid.reshape(-1)] = 0\n",
        "\n",
        "    num = (pred * tgt1h).sum(0) * 2\n",
        "    den = pred.sum(0) + tgt1h.sum(0) + eps\n",
        "    dice = 1 - (num / den).mean()\n",
        "    return dice\n",
        "\n",
        "# loss (CE + Dice)\n",
        "\n",
        "def combined_loss(logits, target, ce_w=0.5, dice_w=0.5):\n",
        "    ce = F.cross_entropy(logits, target, weight=CLASS_WEIGHTS, ignore_index=IGNORE_INDEX)\n",
        "    dice = dice_loss_mc(logits, target, ignore_index=IGNORE_INDEX)\n",
        "    return ce_w*ce + dice_w*dice\n",
        "\n",
        "from torchvision.models.segmentation import fcn_resnet50\n",
        "model = fcn_resnet50(num_classes=NUM_CLASSES).to(device)\n",
        "scaler = GradScaler()\n"
      ],
      "metadata": {
        "id": "syVLyh_tzq2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FCN Train\n",
        "import csv, torch\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "BEST_CKPT   = wpath(\"best_fcn_resnet50_50epochs.pth\")\n",
        "CSV_HISTORY = wpath(\"fcn_training_history.csv\")\n",
        "PLOT_PNG    = wpath(\"fcn_training_results.png\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def confusion_matrix(pred, target, C, ignore_index=IGNORE_INDEX):\n",
        "    valid = (target != ignore_index)\n",
        "    t = target[valid].view(-1)\n",
        "    p = pred[valid].view(-1)\n",
        "    return torch.bincount(t*C + p, minlength=C*C).reshape(C, C).to(torch.long)\n",
        "\n",
        "def metrics_from_cm(cm):\n",
        "    cm = cm.float()\n",
        "    TP = torch.diag(cm); FP = cm.sum(0) - TP; FN = cm.sum(1) - TP\n",
        "    iou_c  = TP / (TP + FP + FN).clamp(min=1)\n",
        "    dice_c = (2*TP) / (2*TP + FP + FN).clamp(min=1)\n",
        "    acc    = TP.sum() / cm.sum().clamp(min=1)\n",
        "    prec_c = TP / (TP + FP).clamp(min=1)\n",
        "    rec_c  = TP / (TP + FN).clamp(min=1)\n",
        "    f1_c   = 2*prec_c*rec_c / (prec_c + rec_c).clamp(min=1e-12)\n",
        "    return {\n",
        "        \"mean_iou\": iou_c.mean().item(),\n",
        "        \"mean_dice\": dice_c.mean().item(),\n",
        "        \"accuracy\": acc.item(),\n",
        "        \"mean_precision\": prec_c.mean().item(),\n",
        "        \"mean_recall\": rec_c.mean().item(),\n",
        "        \"mean_f1\": f1_c.mean().item()\n",
        "    }\n",
        "\n",
        "#Optimizasyon & LR planı\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "optimizer = AdamW(model.parameters(), lr=8e-4, weight_decay=1e-4)\n",
        "\n",
        "EPOCHS   = 50\n",
        "PATIENCE = 10\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=8e-4,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    epochs=EPOCHS,\n",
        "    pct_start=0.1, div_factor=10.0, final_div_factor=100.0\n",
        ")\n",
        "\n",
        "with open(CSV_HISTORY, \"w\", newline=\"\") as f:\n",
        "    csv.writer(f).writerow([\"epoch\",\"train_loss\",\"val_loss\",\"mIoU\",\"Acc\",\"Dice\",\"F1\"])\n",
        "\n",
        "history = {\"epoch\":[], \"train_loss\":[], \"val_loss\":[], \"mIoU\":[], \"Acc\":[], \"Dice\":[], \"F1\":[]}\n",
        "best = {\"epoch\":0, \"mIoU\":-1.0, \"metrics\":None}\n",
        "\n",
        "epochs_no_improve = 0\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    # TRAIN\n",
        "    model.train(); total_loss = 0.0\n",
        "    for xb, yb, _ in tqdm(train_loader, desc=f\"Train {epoch}/{EPOCHS}\", leave=False):\n",
        "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast():\n",
        "            out = model(xb)\n",
        "            logits = out[\"out\"] if isinstance(out, dict) else out\n",
        "            loss = combined_loss(logits, yb)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    train_loss = total_loss / max(1, len(train_loader.dataset))\n",
        "\n",
        "    #VAL\n",
        "    model.eval(); cm_total = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.long, device=device); val_loss=0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, _ in tqdm(val_loader, desc=\"Val\", leave=False):\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            out = model(xb)\n",
        "            logits = out[\"out\"] if isinstance(out, dict) else out\n",
        "            val_loss += combined_loss(logits, yb).item() * xb.size(0)\n",
        "            preds = logits.argmax(1)\n",
        "            cm_total += confusion_matrix(preds, yb, C=NUM_CLASSES, ignore_index=IGNORE_INDEX)\n",
        "    val_loss /= max(1, len(val_loader.dataset))\n",
        "    mets = metrics_from_cm(cm_total)\n",
        "\n",
        "    # LOG & CSV\n",
        "    history[\"epoch\"].append(epoch)\n",
        "    for k,v in [(\"train_loss\",train_loss),(\"val_loss\",val_loss),\n",
        "                (\"mIoU\",mets[\"mean_iou\"]),(\"Acc\",mets[\"accuracy\"]),\n",
        "                (\"Dice\",mets[\"mean_dice\"]),(\"F1\",mets[\"mean_f1\"])]:\n",
        "        history[k].append(v)\n",
        "    with open(CSV_HISTORY, \"a\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow([epoch, f\"{train_loss:.6f}\", f\"{val_loss:.6f}\",\n",
        "                                f\"{mets['mean_iou']:.6f}\", f\"{mets['accuracy']:.6f}\",\n",
        "                                f\"{mets['mean_dice']:.6f}\", f\"{mets['mean_f1']:.6f}\"])\n",
        "\n",
        "    print(f\"[{epoch:03d}] Train:{train_loss:.4f} | Val:{val_loss:.4f} | \"\n",
        "          f\"mIoU:{mets['mean_iou']:.3f} Dice:{mets['mean_dice']:.3f} Acc:{mets['accuracy']:.3f} F1:{mets['mean_f1']:.3f}\")\n",
        "\n",
        "    # BEST SAVE (mIoU) + Early Stop\n",
        "    if mets[\"mean_iou\"] > best[\"mIoU\"]:\n",
        "        best.update({\"epoch\":epoch, \"mIoU\":mets[\"mean_iou\"], \"metrics\":mets})\n",
        "        torch.save({\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"metrics\": mets,\n",
        "            \"history\": history,\n",
        "            \"config\": {\"num_classes\": NUM_CLASSES, \"ignore_index\": IGNORE_INDEX}\n",
        "        }, BEST_CKPT)\n",
        "        print(f\" Best updated: mIoU={mets['mean_iou']:.4f} → {BEST_CKPT}\")\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(f\" Early stopping @ {epoch}. Best mIoU={best['mIoU']:.4f} (epoch {best['epoch']})\")\n",
        "            break\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\")\n",
        "plt.plot(history[\"epoch\"], history[\"val_loss\"],   label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.title(\"FCN Training Loss\")\n",
        "plt.tight_layout(); plt.savefig(PLOT_PNG); plt.close()\n",
        "\n",
        "print(\"FCN eğitim tamam. Best epoch:\", best[\"epoch\"], \"mIoU:\", f\"{best['mIoU']:.4f}\")\n",
        "print(\"Saved:\", BEST_CKPT, \"\\nLogs:\", CSV_HISTORY, \"\\nPlots:\", PLOT_PNG)\n"
      ],
      "metadata": {
        "id": "PZ8y2ot-0ube"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, re, csv, time\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def wpath(p):\n",
        "    base = \"/kaggle/working\"\n",
        "    return p if p.startswith(base) else os.path.join(base, p)\n",
        "\n",
        "COLOR_MAP = {\n",
        "    0:(255,255,255), 1:(255,0,0), 2:(255,255,0),\n",
        "    3:(0,0,255), 4:(159,129,183), 5:(0,255,0), 6:(255,195,128)\n",
        "}\n",
        "PALETTE = np.array([COLOR_MAP[i] for i in range(0,7)], dtype=np.uint8)\n",
        "\n",
        "def colorize(mask_hw: np.ndarray) -> np.ndarray:\n",
        "    rgb = np.zeros((mask_hw.shape[0], mask_hw.shape[1], 3), dtype=np.uint8)\n",
        "    valid = (mask_hw >= 0) & (mask_hw < len(PALETTE))\n",
        "    rgb[valid] = PALETTE[mask_hw[valid]]\n",
        "    return rgb\n",
        "\n",
        "@torch.no_grad()\n",
        "def confusion_matrix(pred, target, C, ignore_index=None):\n",
        "    valid = (target != ignore_index) if ignore_index is not None else torch.ones_like(target, dtype=torch.bool)\n",
        "    t = target[valid].view(-1)\n",
        "    p = pred[valid].view(-1)\n",
        "    return torch.bincount(t*C + p, minlength=C*C).reshape(C, C).to(torch.long)\n",
        "\n",
        "def metrics_from_cm(cm: torch.Tensor):\n",
        "    eps = 1e-6\n",
        "    cm = cm.float()\n",
        "    TP = torch.diag(cm)\n",
        "    FP = cm.sum(0) - TP\n",
        "    FN = cm.sum(1) - TP\n",
        "    TN = cm.sum() - (TP + FP + FN)\n",
        "\n",
        "    iou_c  = TP / (TP + FP + FN + eps)\n",
        "    dice_c = 2*TP / (2*TP + FP + FN + eps)\n",
        "    prec_c = TP / (TP + FP + eps)\n",
        "    rec_c  = TP / (TP + FN + eps)\n",
        "    f1_c   = 2*prec_c*rec_c / (prec_c + rec_c + eps)\n",
        "    acc    = (TP + TN) / (TP + FP + FN + TN + eps)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc.mean().item(),\n",
        "        \"global_accuracy\": (TP.sum()/cm.sum()).item(),\n",
        "        \"mean_iou\": iou_c.mean().item(),\n",
        "        \"mean_dice\": dice_c.mean().item(),\n",
        "        \"mean_precision\": prec_c.mean().item(),\n",
        "        \"mean_recall\": rec_c.mean().item(),\n",
        "        \"mean_f1\": f1_c.mean().item(),\n",
        "        \"per_class_iou\": iou_c.cpu().numpy(),\n",
        "        \"per_class_dice\": dice_c.cpu().numpy(),\n",
        "        \"per_class_precision\": prec_c.cpu().numpy(),\n",
        "        \"per_class_recall\": rec_c.cpu().numpy(),\n",
        "        \"per_class_f1\": f1_c.cpu().numpy(),\n",
        "        \"per_class_acc\": acc.cpu().numpy(),\n",
        "    }\n",
        "\n",
        "import torchvision.models.segmentation as segm\n",
        "\n",
        "CKPT_PATH = wpath(\"best_fcn_resnet50_50epochs.pth\")\n",
        "assert os.path.isfile(CKPT_PATH), f\"Checkpoint yok: {CKPT_PATH}\"\n",
        "\n",
        "fcn_model = segm.fcn_resnet50(weights=None, num_classes=NUM_CLASSES).to(device).eval()\n",
        "\n",
        "def load_ckpt_safe(path):\n",
        "    try:\n",
        "        from torch.serialization import add_safe_globals\n",
        "        import numpy as np\n",
        "        add_safe_globals([np.core.multiarray._reconstruct])\n",
        "        state = torch.load(path, map_location=\"cpu\", weights_only=True)\n",
        "        if isinstance(state, dict) and \"state_dict\" in state:\n",
        "            return state[\"state_dict\"]\n",
        "        return state\n",
        "    except Exception as e:\n",
        "        print(f\"[info] weights_only=True olmadı: {e}\")\n",
        "        return torch.load(path, map_location=\"cpu\", weights_only=False)\n",
        "\n",
        "state_dict = load_ckpt_safe(CKPT_PATH)\n",
        "\n",
        "if isinstance(state_dict, dict) and \"model_state_dict\" in state_dict:\n",
        "    state_dict = state_dict[\"model_state_dict\"]\n",
        "fcn_model.load_state_dict(state_dict)\n",
        "\n",
        "cm_total = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.long, device=device)\n",
        "with torch.no_grad():\n",
        "    for xb, yb, _ in tqdm(val_loader, desc=\"FCN Validation\"):\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        out = fcn_model(xb)\n",
        "        logits = out[\"out\"] if isinstance(out, dict) else out\n",
        "        preds = logits.argmax(1)\n",
        "        cm_total += confusion_matrix(preds, yb, C=NUM_CLASSES, ignore_index=IGNORE_INDEX)\n",
        "\n",
        "mets = metrics_from_cm(cm_total)\n",
        "\n",
        "\n",
        "print(f\" Overall Pixel Accuracy: {mets['global_accuracy']:.4f}\")\n",
        "print(f\"Mean (per-class) Accuracy: {mets['accuracy']:.4f}\")\n",
        "print(f\"Mean IoU: {mets['mean_iou']:.4f}\")\n",
        "print(f\" Mean Dice: {mets['mean_dice']:.4f}\")\n",
        "print(f\" Mean Precision: {mets['mean_precision']:.4f}\")\n",
        "print(f\"Mean Recall: {mets['mean_recall']:.4f}\")\n",
        "print(f\" Mean F1-Score: {mets['mean_f1']:.4f}\")\n",
        "\n",
        "CLASS_NAMES = ['Background','Building','Road','Water','Barren','Forest','Agriculture']\n",
        "\n",
        "for i, name in enumerate(CLASS_NAMES):\n",
        "    print(f\"{name:>11} \"\n",
        "          f\"{mets['per_class_iou'][i]:.3f} {mets['per_class_dice'][i]:.3f} \"\n",
        "          f\"{mets['per_class_acc'][i]:.3f} {mets['per_class_precision'][i]:.3f} \"\n",
        "          f\"{mets['per_class_recall'][i]:.3f} {mets['per_class_f1'][i]:.3f}\")\n",
        "\n",
        "CSV_OVERALL = wpath(\"fcn_metrics_overall.csv\")\n",
        "CSV_PERCLS  = wpath(\"fcn_metrics_per_class.csv\")\n",
        "with open(CSV_OVERALL, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"metric\",\"value\"])\n",
        "    for k in [\"global_accuracy\",\"accuracy\",\"mean_iou\",\"mean_dice\",\"mean_precision\",\"mean_recall\",\"mean_f1\"]:\n",
        "        w.writerow([k, f\"{mets[k]:.6f}\"])\n",
        "with open(CSV_PERCLS, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"class_id\",\"class_name\",\"IoU\",\"Dice\",\"Acc\",\"Precision\",\"Recall\",\"F1\"])\n",
        "    for i, name in enumerate(CLASS_NAMES):\n",
        "        w.writerow([\n",
        "            i, name,\n",
        "            f\"{mets['per_class_iou'][i]:.6f}\",\n",
        "            f\"{mets['per_class_dice'][i]:.6f}\",\n",
        "            f\"{mets['per_class_acc'][i]:.6f}\",\n",
        "            f\"{mets['per_class_precision'][i]:.6f}\",\n",
        "            f\"{mets['per_class_recall'][i]:.6f}\",\n",
        "            f\"{mets['per_class_f1'][i]:.6f}\",\n",
        "        ])\n",
        "print(\"CSV'ler kaydedildi:\", CSV_OVERALL, \"ve\", CSV_PERCLS)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_and_save(dl, save_dir, desc):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    for xb, _, names in tqdm(dl, desc=desc):\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        out = fcn_model(xb)\n",
        "        logits = out[\"out\"] if isinstance(out, dict) else out\n",
        "        preds  = logits.argmax(1).cpu().numpy().astype(np.uint8)\n",
        "        for p, name in zip(preds, names):\n",
        "            Image.fromarray(colorize(p)).save(os.path.join(save_dir, name))\n",
        "\n",
        "SAVE_VAL  = wpath(\"fcn_preds_val\")\n",
        "SAVE_TEST = wpath(\"fcn_preds_test\")\n",
        "predict_and_save(val_loader,  SAVE_VAL,  \"VAL predict→PNG (FCN, B palette)\")\n",
        "\n",
        "print(\"VAL preds:\", SAVE_VAL)\n",
        "\n",
        "TILE = IMG_SIZE\n",
        "VAL_IMG_DIR = SPLITS[\"val\"][\"img\"]\n",
        "PRED_DIR    = SAVE_VAL\n",
        "\n",
        "rx = re.compile(r\"^(?P<base>.+)_r(?P<r>\\d+)_c(?P<c>\\d+)\\.png$\")\n",
        "\n",
        "def draw_grid(img, tile=TILE, lw=1):\n",
        "    out = img.copy()\n",
        "    for y in range(tile, img.shape[0], tile): out[y-lw:y+lw, :] = 255\n",
        "    for x in range(tile, img.shape[1], tile): out[:, x-lw:x+lw] = 255\n",
        "    return out\n",
        "\n",
        "def find_base_ids(img_dir):\n",
        "    files = sorted(glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "    bases = {}\n",
        "    for fp in files:\n",
        "        m = rx.match(os.path.basename(fp))\n",
        "        if not m: continue\n",
        "        b = m.group(\"base\"); r = int(m.group(\"r\")); c = int(m.group(\"c\"))\n",
        "        R, C, cnt = bases.get(b, (0,0,0))\n",
        "        bases[b] = (max(R, r+1), max(C, c+1), cnt+1)\n",
        "    return [b for b,_ in sorted(bases.items(), key=lambda kv: -kv[1][2])]\n",
        "\n",
        "def reconstruct_full(img_dir, base):\n",
        "    pats = sorted(glob.glob(os.path.join(img_dir, f\"{base}_r*_c*.png\")))\n",
        "    assert pats, f\"Patch yok: {base}\"\n",
        "    rs, cs = [], []\n",
        "    for p in pats:\n",
        "        m = rx.match(os.path.basename(p)); rs.append(int(m.group(\"r\"))); cs.append(int(m.group(\"c\")))\n",
        "    R, C = max(rs)+1, max(cs)+1\n",
        "    H, W = R*TILE, C*TILE\n",
        "    full_img = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for p in pats:\n",
        "        m = rx.match(os.path.basename(p)); r, c = int(m.group(\"r\")), int(m.group(\"c\"))\n",
        "        img = np.array(Image.open(p).convert(\"RGB\"))\n",
        "        full_img[r*TILE:(r+1)*TILE, c*TILE:(c+1)*TILE] = img\n",
        "    return full_img\n",
        "\n",
        "BASE = \"3515\"\n",
        "base_ids = find_base_ids(VAL_IMG_DIR)\n",
        "if BASE not in base_ids and len(base_ids)>0:\n",
        "    BASE = base_ids[0]\n",
        "\n",
        "full_img      = reconstruct_full(VAL_IMG_DIR, BASE)\n",
        "full_img_grid = draw_grid(full_img, tile=TILE, lw=1)\n",
        "\n",
        "pred_patch_files = sorted(glob.glob(os.path.join(PRED_DIR, f\"{BASE}_r*_c*.png\")))\n",
        "rs, cs = [], []\n",
        "for p in pred_patch_files:\n",
        "    m = rx.match(os.path.basename(p)); rs.append(int(m.group(\"r\"))); cs.append(int(m.group(\"c\")))\n",
        "R, C = max(rs)+1, max(cs)+1\n",
        "H, W = R*TILE, C*TILE\n",
        "full_pred_rgb = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "for p in pred_patch_files:\n",
        "    m = rx.match(os.path.basename(p)); r, c = int(m.group(\"r\")), int(m.group(\"c\"))\n",
        "    rgb = np.array(Image.open(p).convert(\"RGB\"))\n",
        "    full_pred_rgb[r*TILE:(r+1)*TILE, c*TILE:(c+1)*TILE] = rgb\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.subplot(1,3,1); plt.imshow(full_img);      plt.title(f\"Image (base={BASE})\"); plt.axis('off')\n",
        "plt.subplot(1,3,2); plt.imshow(full_img_grid); plt.title(\"Patch Grid\");           plt.axis('off')\n",
        "plt.subplot(1,3,3); plt.imshow(full_pred_rgb); plt.title(\"FCN Prediction\");       plt.axis('off')\n",
        "plt.tight_layout()\n",
        "OUT_FULL = wpath(f\"vis_full_grid_pred_{BASE}_fcn.png\")\n",
        "plt.savefig(OUT_FULL, dpi=150); plt.close()\n",
        "print(\" Kaydedildi:\", OUT_FULL)\n",
        "\n",
        "import pandas as pd\n",
        "HIST_CSV = wpath(\"fcn_training_history.csv\")\n",
        "if os.path.isfile(HIST_CSV):\n",
        "    dfh = pd.read_csv(HIST_CSV)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    if \"train_loss\" in dfh.columns and \"val_loss\" in dfh.columns:\n",
        "        plt.plot(dfh[\"train_loss\"], label=\"Train Loss\")\n",
        "        plt.plot(dfh[\"val_loss\"],   label=\"Val Loss\")\n",
        "    else:\n",
        "\n",
        "        tr_col = \"train_loss\" if \"train_loss\" in dfh.columns else (\"train\" if \"train\" in dfh.columns else dfh.columns[0])\n",
        "        va_col = \"val_loss\"   if \"val_loss\"   in dfh.columns else (\"val\"   if \"val\"   in dfh.columns else dfh.columns[1])\n",
        "        plt.plot(dfh[tr_col], label=\"Train Loss\")\n",
        "        plt.plot(dfh[va_col], label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"FCN Training & Validation Loss\")\n",
        "    plt.legend(); plt.grid(True)\n",
        "    OUT_LOSS = wpath(\"fcn_loss_curve.png\")\n",
        "    plt.savefig(OUT_LOSS, dpi=150); plt.close()\n",
        "    print(f\"Loss grafiği kaydedildi: {OUT_LOSS}\")\n",
        "else:\n",
        "    print(f\" Loss history CSV bulunamadı: {HIST_CSV}\")\n"
      ],
      "metadata": {
        "id": "IoxtbvCD-j3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Presentation\n"
      ],
      "metadata": {
        "id": "P5uUiKXzCwyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _ensure_out(outdir):\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "def _read_overall(path_overall):\n",
        "    df = pd.read_csv(path_overall)\n",
        "    if {\"metric\", \"value\"}.issubset(df.columns):\n",
        "        return {row[\"metric\"]: float(row[\"value\"]) for _, row in df.iterrows()}\n",
        "    return {k: float(v) for k, v in df.iloc[0].to_dict().items() if pd.api.types.is_number(v)}\n",
        "\n",
        "def _read_perclass(path_perclass):\n",
        "    df = pd.read_csv(path_perclass)\n",
        "    rename_map = {}\n",
        "    for c in df.columns:\n",
        "        if c.lower() == \"iou\": rename_map[c] = \"IoU\"\n",
        "        if c.lower() == \"dice\": rename_map[c] = \"Dice\"\n",
        "        if c.lower() == \"precision\": rename_map[c] = \"Precision\"\n",
        "        if c.lower() == \"recall\": rename_map[c] = \"Recall\"\n",
        "        if c.lower() in (\"f1\",\"f1_score\",\"f1-score\"): rename_map[c] = \"F1\"\n",
        "        if c.lower() in (\"accuracy\",\"acc\"): rename_map[c] = \"Accuracy\"\n",
        "        if c.lower() in (\"class\",\"classname\",\"class_name\"): rename_map[c] = \"class_name\"\n",
        "    df = df.rename(columns=rename_map)\n",
        "    if \"class_name\" not in df.columns:\n",
        "        df[\"class_name\"] = [f\"Class {i}\" for i in range(len(df))]\n",
        "    for col in [\"IoU\",\"Dice\",\"Precision\",\"Recall\",\"F1\",\"Accuracy\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "def _plot_loss(history_csv, out_png, title=\"Training & Validation Loss\"):\n",
        "    if not os.path.isfile(history_csv):\n",
        "        return\n",
        "    df = pd.read_csv(history_csv)\n",
        "    tr_col = None\n",
        "    for k in [\"train_loss\",\"train\",\"Train\",\"training_loss\"]:\n",
        "        if k in df.columns: tr_col = k; break\n",
        "    va_col = None\n",
        "    for k in [\"val_loss\",\"val\",\"Val\",\"validation_loss\"]:\n",
        "        if k in df.columns: va_col = k; break\n",
        "    if tr_col is None or va_col is None:\n",
        "        return\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(df[tr_col].values, label=\"Train Loss\")\n",
        "    plt.plot(df[va_col].values, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(title)\n",
        "    plt.grid(True, alpha=0.3); plt.legend()\n",
        "    plt.tight_layout(); plt.savefig(out_png, dpi=150); plt.close()\n",
        "\n",
        "def _bar(values, labels, ylabel, title, out_png, ylim01=True):\n",
        "    plt.figure(figsize=(9,5))\n",
        "    x = np.arange(len(labels))\n",
        "    vals = np.array(values, dtype=float)\n",
        "    plt.bar(x, vals)\n",
        "    plt.xticks(x, labels, rotation=20)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    if ylim01:\n",
        "        plt.ylim(0, 1.0)\n",
        "    for i,v in enumerate(vals):\n",
        "        plt.text(i, v + 0.01*(1 if ylim01 else max(vals, default=1)), f\"{v:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
        "    plt.tight_layout(); plt.savefig(out_png, dpi=150); plt.close()\n",
        "\n",
        "def generate_model_figures(\n",
        "    model_name: str,\n",
        "    overall_csv: str,\n",
        "    perclass_csv: str,\n",
        "    history_csv: str = None,\n",
        "    outdir: str = \"./figures\"\n",
        "):\n",
        "    outdir = os.path.join(outdir, model_name.replace(\" \", \"_\").lower())\n",
        "    _ensure_out(outdir)\n",
        "\n",
        "    overall = _read_overall(overall_csv)\n",
        "    percls  = _read_perclass(perclass_csv)\n",
        "\n",
        "    if history_csv:\n",
        "        _plot_loss(history_csv, os.path.join(outdir, \"loss_curve.png\"), f\"{model_name} — Training & Validation Loss\")\n",
        "\n",
        "    keys = []\n",
        "    labels_map = {\n",
        "        \"global_accuracy\":\"Overall Acc\",\n",
        "        \"accuracy\":\"Mean Acc\",\n",
        "        \"mean_iou\":\"Mean IoU\",\n",
        "        \"mean_dice\":\"Mean Dice\",\n",
        "        \"mean_precision\":\"Mean Precision\",\n",
        "        \"mean_recall\":\"Mean Recall\",\n",
        "        \"mean_f1\":\"Mean F1\",\n",
        "    }\n",
        "    for k in [\"global_accuracy\",\"accuracy\",\"mean_iou\",\"mean_dice\",\"mean_precision\",\"mean_recall\",\"mean_f1\"]:\n",
        "        if k in overall: keys.append(k)\n",
        "\n",
        "    if keys:\n",
        "        _bar(\n",
        "            [overall[k] for k in keys],\n",
        "            [labels_map.get(k,k) for k in keys],\n",
        "            ylabel=\"Score\",\n",
        "            title=f\"{model_name} — Overall Metrics\",\n",
        "            out_png=os.path.join(outdir, \"overall_bars.png\"),\n",
        "            ylim01=True\n",
        "        )\n",
        "        pd.DataFrame([overall]).to_csv(os.path.join(outdir, \"overall_table.csv\"), index=False)\n",
        "\n",
        "    class_labels = percls[\"class_name\"].tolist()\n",
        "\n",
        "    metric_list = [(\"IoU\",\"perclass_iou.png\"),\n",
        "                   (\"Dice\",\"perclass_dice.png\"),\n",
        "                   (\"Precision\",\"perclass_precision.png\"),\n",
        "                   (\"Recall\",\"perclass_recall.png\"),\n",
        "                   (\"F1\",\"perclass_f1.png\")]\n",
        "\n",
        "    if \"Accuracy\" in percls.columns:\n",
        "        metric_list.append((\"Accuracy\",\"perclass_accuracy.png\"))\n",
        "\n",
        "    for met, filename in metric_list:\n",
        "        if met in percls.columns:\n",
        "            _bar(\n",
        "                percls[met].values,\n",
        "                class_labels,\n",
        "                ylabel=met,\n",
        "                title=f\"{model_name} — Per-class {met}\",\n",
        "                out_png=os.path.join(outdir, filename),\n",
        "                ylim01=True\n",
        "            )\n",
        "\n",
        "    print(f\"{model_name}: çıktılar -> {outdir}\")\n",
        "\n",
        "# 1) U-Net\n",
        "generate_model_figures(\n",
        "    model_name   =\"U-Net (ResNet50)\",\n",
        "    overall_csv  =\"/kaggle/working/unet_50epochs_metrics_overall.csv\",\n",
        "    perclass_csv =\"/kaggle/working/unet_50epochs_metrics_per_class.csv\",\n",
        "    history_csv  =\"/kaggle/working/unet_training_history.csv\",\n",
        "    outdir       =\"/kaggle/working/presentation_figs\"\n",
        ")\n",
        "\n",
        "# 2) DeepLabV3+\n",
        "generate_model_figures(\n",
        "    model_name   =\"DeepLabV3+ (ResNet50)\",\n",
        "    overall_csv  =\"/kaggle/working/deeplabv3plus_metrics_overall.csv\",\n",
        "    perclass_csv =\"/kaggle/working/deeplabv3plus_metrics_per_class.csv\",\n",
        "    history_csv  =\"/kaggle/working/deeplab_training_history.csv\",\n",
        "    outdir       =\"/kaggle/working/presentation_figs\"\n",
        ")\n",
        "\n",
        "# 3) FCN\n",
        "generate_model_figures(\n",
        "    model_name   =\"FCN (ResNet50)\",\n",
        "    overall_csv  =\"/kaggle/working/fcn_metrics_overall.csv\",\n",
        "    perclass_csv =\"/kaggle/working/fcn_metrics_per_class.csv\",\n",
        "    history_csv  =\"/kaggle/working/fcn_training_history.csv\",\n",
        "    outdir       =\"/kaggle/working/presentation_figs\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "QjSFvppFek2j",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VnxGynnxqpME"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOtGJZv5cLEuGJDhY/2oFTN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}